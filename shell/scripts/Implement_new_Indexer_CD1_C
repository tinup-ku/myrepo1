#!/bin/ksh
# NOTE: New Changes for CD1.
# 1. We'll have ONLY /opt/splunkindex_data 
# 2. ${SPLUNK_ETC}/splunk-launch.conf, both SPLUNK_DB/SPLUNK_DBHOT=/opt/splunkindex_data
# 3. Revise ser10966some_loc:/root/scripts/Convert_Splunk_to_svcacct to accomodate 1 and 2 
#    above.
####################################################################################
# This script performs the followings
# 1. Creates 140GB lvm, /dev/rootvg/splunklv, from OS RAID1 223.0 GB Virtual Disk 0
# 2. Each Indexer has 16 x 1.745TB SSDs, will be configured as single virtual disk
#    LVM Physical Volume: /dev/sdb1  splunkvg lvm2 a--   24.44t      0
#    LVM vg: splunkvg
#    Splunk Hot and Cold LVM:/dev/splunkvg/splunkindex_lv
#    Splunk Hot and Cold File system: /opt/splunkindex_data

#    Note: For RAID50, when creating virtual disk via perccli, option pdperarray
#    needs to specify, ie, pdperarray=8
# 3. Once ext4 file systems described in 1-2 created and local mount table updated,
#    install splunk-8.1.5.
#    Note: In order to maintain the Index cluster splunk start/stop consistency,
#    option "-systemd-managed 1" must be specified.
# 4. Install below RHEL packages
#    kernel-headers,glibc-headers,gcc,gdb,zip,unzip,nc,nmap
# 5. Set ulimit's soft+hard in /etc/security/limits.conf to 262144
# 6. Set splunk fs.file-max = 2048000 in /etc/sysctl.conf
# 7. Set nproc's soft+hard in /etc/security/limits.d/20-nproc.conf to 131072
# 8. Disable Transparent Huge Pages (THP) as recommended by Splunk
# 9. Disable kvstore recommends by Splunk on Indexers.
#
# Below is the disks layout on new Dell 740xd
# RHEL8 OS RAID1: slots 24-25
# Splunk Hot and Cold RAID50 SSDs slots 0-15: 16 x 1.745 TB
#  - Hot + Cold RAID50 /opt/splunkindex_data: 25TB
#
# ------------------------------------------------------------------------------
# DG Arr Row EID:Slot DID Type   State BT       Size PDC  PI SED DS3  FSpace TR
# ------------------------------------------------------------------------------
# 0 -   -   -        -   RAID1  Optl  N  446.625 GB dflt N  N   dflt N      N
# 0 0   -   -        -   RAID1  Optl  N  446.625 GB dflt N  N   dflt N      N
# 0 0   0   64:24    24  DRIVE  Onln  N  446.625 GB dflt N  N   dflt -      N
# 0 0   1   64:25    25  DRIVE  Onln  N  446.625 GB dflt N  N   dflt -      N
# 1 -   -   -        -   RAID50 Optl  N   24.443 TB dflt N  N   dflt N      N
# 1 0   -   -        -   RAID5  Optl  N   12.221 TB dflt N  N   dflt N      N
# 1 0   0   64:0     0   DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 0   1   64:1     1   DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 0   2   64:2     2   DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 0   3   64:3     3   DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 0   4   64:4     4   DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 0   5   64:5     5   DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 0   6   64:6     6   DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 0   7   64:7     7   DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 1   -   -        -   RAID5  Optl  N   12.221 TB dflt N  N   dflt N      N
# 1 1   0   64:8     8   DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 1   1   64:9     9   DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 1   2   64:10    10  DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 1   3   64:11    11  DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 1   4   64:12    12  DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 1   5   64:13    13  DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 1   6   64:14    14  DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
# 1 1   7   64:15    15  DRIVE  Onln  N    1.745 TB dflt N  N   dflt -      N
####################################################################################
# Written by user1 | T O S Platform A
SPLUNK_HOME=/opt/splunk
SPLUNK_BIN=${SPLUNK_HOME}/bin
SPLUNK_LOCAL=${SPLUNK_HOME}/etc/system/local
splunk_version="splunk-8.1.5-9c0c082e4596.x86_64"
env_=`uname -n|grep -o '...$'`
date_=$(date '+%a%H%M_%m%d%Y')

[[ `uname -n` = "ser15000some_loc" ]] && {
   echo "Running $0 on wrong node: ser15000some_loc"
   exit
}

rpm -q splunk >/dev/null
[[ "?" = "0" ]] && {
   echo "Splunk installed: $(rpm -q splunk). Abort"
   exit
}

env_=`uname -n|grep -o '...$'`
{
eval `gpg --batch --xyz xyz -d /.splunk` >/dev/null 2>&1
} 2>/dev/null

case ${env_} in
         pdv | bdv )
                     uid=ser_act.dev
                     gid=unx_60231_splunk_admin_dev
                     fqdn="dev.mycorp.com"
                     key=$dev
                     ;;
   some_loc | loc2 | loc3 | loc4 )
                     uid=ser_act.prod
                     gid=unx_9998_access
                     fqdn="some_loc.mycorp.com"
                     key=$prod
                     ;;
                 * )
                     case `uname -n` in
                           ser2* )
                                uid=ser_act.prod
                                gid=unx_9998_access
                                fqdn="us.global.mycorp.com"
                                key=$prod
                                ;;
                            cud*| cut* )
                                uid=ser_act.dev
                                gid=unx_60231_splunk_admin_dev
                                fqdn="us.global.mycorp.com"
                                key=$dev
                                ;;
                     esac
                     ;;
esac


{
# If splunk ${splunk_version} installed then exit
[[ "`rpm -q splunk`" = "${splunk_version}" ]] && {
  echo "${splunk_version} installed. Abort."
  exit
}

check_DISK ()
{
 flag=false
 while [[ "$flag" = "false" ]]
 do
   if [[ ! -b $1 ]]
   then
     echo "Pause for 3 seconds."
     sleep 3s
   else
    flag=true 
   fi
 done 
}

install_abrt ()
{
  # Setting up coredump in case needed for Splunk Troubleshooting"
  # https://access.redhat.com/solutions/56021
  # Note:
  #   1. Core dump file size is set in /etc/abrt/abrt.conf:
  #      Set MaxCrashReportsSize = 30000
  #          DumpLocation = /opt/splunkindex_data/abrt
  #   2. In /etc/abrt/abrt-action-save-package-data.conf
  #      Set OpenGPGCheck = no
  #          ProcessUnpackaged = yes
  #   3. In /etc/abrt/plugins/CCpp.conf
  #      Set MakeCompatCore = yes  
  #
  echo "Verifying abrt abrt-addon-ccpp abrt-tui"
  yum -y install abrt abrt-addon-ccpp abrt-tui
  echo
  rpm -q abrt abrt-addon-ccpp abrt-tui
  echo
  echo "Install ccpp hooks"
  abrt-install-ccpp-hook install
  abrt-install-ccpp-hook is-installed
  echo "EXIT_status=$?"
  echo "Modifying /etc/abrt/abrt-action-save-package-data.conf"
  sed -ie 's/ProcessUnpackaged = no/ProcessUnpackaged = yes/g' \
       -e 's/OpenGPGCheck = yes/OpenGPGCheck = no/g' \
          /etc/abrt/abrt-action-save-package-data.conf

  echo
  echo "Verifying OpenGPGCheck and ProcessUnpackaged in /etc/abrt/abrt-action-save-package-data.conf"
  egrep '^OpenGPGCheck|^ProcessUnpackaged' /etc/abrt/abrt-action-save-package-data.conf
  echo
  echo "Modifying /etc/abrt/plugins/CCpp.conf: MakeCompatCore = no to yes"
  sed -i 's/MakeCompatCore = no/MakeCompatCore = yes/g' /etc/abrt/plugins/CCpp.conf
  echo "Verifying /etc/abrt/plugins/CCpp.conf:"
  grep '^MakeCompatCore' /etc/abrt/plugins/CCpp.conf
  echo
  echo "/etc/abrt/abrt.conf, changing MaxCrashReportsSize to 30GB and DumpLocation = /opt/splunkindex_data/abrt"
  sed -i -e 's/MaxCrashReportsSize = 5000/MaxCrashReportsSize = 30000/g' \
         -e '/#DumpLocation =/a DumpLocation = /opt/splunkindex_data/abrt' /etc/abrt/abrt.conf
  echo "Verifying /etc/abrt/abrt.conf:"
  egrep '^MaxCrashReportsSize|^DumpLocation' /etc/abrt/abrt.conf
  echo
  echo "Enable  Autoreporting feature"
  abrt-auto-reporting enabled
}

# Check if perccli installed.
rpm -q perccli >/dev/null
[[ "$?" != "0" ]] && {
   umount -l /mnt
   mount share_server.dev.mycorp.com:/infra/loc /mnt
   cd /mnt/Splunk/pkgs && rpm -ivh perccli-1.11.03-1.noarch.rpm
   ln -s /opt/MegaRAID/perccli/perccli64 /usr/local/bin/perccli
}
   
# Allocate 140G out of 381.59g /opt/splunk on OS RAID1, rootvg
# Check if splunklv created
lvs |grep splunklv >/dev/null
if [[ "$?" != "0" ]]
then 
   PFree=`pvs|awk '/rootvg/{print $NF}'|sed 's/<//g'`
   if [[ "${PFree}" = "381.59g" ]] || [[ "${PFree}" = "381.50g" ]] || [[ "${PFree}" = "382.06g" ]]
   then
      echo "Creating 140GB lvm: splunklv"
      lvcreate -y -L140G -v rootvg -n splunklv
      echo "Creating file system: /dev/rootvg/splunklv"
      mkfs.ext4 -m 1 /dev/rootvg/splunklv
      [[ ! -d /opt/splunk ]] && mkdir /opt/splunk
      # Add /dev/mapper/rootvg-splunklv /opt/splunk     ext4     defaults        0 0
      echo "Updating local mount table: /opt/splunk"
      sed -i '$a/dev/mapper/rootvg-splunklv /opt/splunk	ext4	defaults	0 0' /etc/fstab
      mount |grep -v 'index'| grep '/opt/splunk' >/dev/null
      [[ "$?" != "0" ]] && {
         echo "Mounting /opt/splunk"
         mount /opt/splunk
      }
   else
      echo "No space available to configure /opt/splunk filesystem"
      exit
   fi
else
   echo "/dev/rootvg/splunklv already created. Skip."
fi

# Create virtual disk, /dev/sdb, via perccli utility
#ssd_drives=`perccli /c0/eall/s0-15 show|awk '/SATA SSD/{print $1}'|sed 's/64://g'`
# On Dell 750xd
ssd_drives=`perccli /c0/eall/s0-15 show|awk '/SAS  SSD/{print $1}'|sed 's/64://g'`
ssd_drives=`echo ${ssd_drives}|sed 's/ /,/g'`

[[ "${ssd_drives}" = "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15" ]] && {
   echo "Creating virtual RAID50 for Splunk Hot and Cold FS"
   echo "SSD Slots: $ssd_drives"
   echo "perccli /c0 add vd type=raid50 drives=64:0-15 pdperarray=8"

   # Before creating, check if already created.
   perccli /c0/v1 show|grep -w 'RAID50' >/dev/null
   if [[ "$?" != "0" ]]
   then
      perccli /c0 add vd type=raid50 drives=64:0-15 pdperarray=8

      # Verifying if virtual drive created.
      # Comment out below 9/26/2022 due to $CLUSTER's CD1_C_DC7_F-core_site2
      # Dell 750xd
      #v1_size=`perccli /c0/vall show|awk '/RAID50/{print $(NF -1)}'`
      #[[ "${v1_size}" = "24.443" ]] && {
          echo "Creating /opt/splunkindex_data filesystem"
          # Is it?
          # Disk /dev/sdb: 447.1 GiB, 480036847616 bytes, 937571968 sectors
          # Disk /dev/sda: 24.5 TiB, 26876026290176 bytes, 52492238848 sectors
          root_disk=$(fdisk -l|grep '/dev/sd'|grep '^Disk'|awk '/447.1 GiB/{print $2}'|sed 's/://g')
          if [[ "${root_disk}" = "/dev/sdb" ]]
          then
             DISK=/dev/sda
          else
             DISK=/dev/sdb
          fi
          check_DISK $DISK
          if [[ -b ${DISK} ]]
          then
            echo "Formatting ${DISK}:"
            parted -s ${DISK} mklabel gpt
            parted -s ${DISK} unit TB mkpart primary ext4 0% 100%
            partprobe
            echo "Creating physical volume ${DISK}1"
            pvcreate ${DISK}1
            echo "Creating splunk volume group: splunkvg"
            vgcreate splunkvg ${DISK}1
            echo
            echo "Creating splunk Index logical volume: splunkindex_lv"
            lvcreate -y -l 100%FREE -n splunkindex_lv splunkvg
            echo
            echo "Creating /dev/splunkvg/splunkindex_lv filesystem"
            mkfs.ext4 -m 1 /dev/splunkvg/splunkindex_lv
          else
            echo "${DISK} doesnot exist. Abort."
            exit
          fi
      #}
   else
      echo "Virtual disk already created:"
      perccli /c0/v1 show|grep -w 'RAID50'
      echo "Skip this step."
   fi
}

# Update local mount table with /opt/splunkindex_data, /opt/splunkindexhot_data
#/dev/splunkvg/coldlv /opt/splunkindex_data ext4 noatime,errors=remount-ro 1 0

grep '/opt/splunkindex_data' /etc/fstab >/dev/null
if [ "$?" != "0" ]
then
   echo '/dev/splunkvg/splunkindex_lv /opt/splunkindex_data ext4 noatime,errors=remount-ro 1 0' >> /etc/fstab
else
   echo "/opt/splunkindex_data ALREADY DEFINED in /etc/fstab"
fi


# Create mount point /opt/splunkindex_data, /opt/splunkindexhot_data, /ELI
mkdir -p /opt/splunkindex_data /ELI 2>/dev/null
mount /opt/splunkindex_data 2>/dev/null

# Install splunk 8.1.5: splunk-8.1.5-9c0c082e4596-linux-2.6-x86_64.rpm
echo "Installing splunk-8.1.5-9c0c082e4596-linux-2.6-x86_64.rpm"
mount|grep '^share_server.dev.mycorp.com:/infra/loc' >/dev/null
[[ "$?" != "0" ]] && mount share_server.dev.mycorp.com:/infra/loc /mnt
cd /mnt/Splunk/8.1.5 && rpm -ivh splunk-latest-x86_64.rpm

echo "Creating ${SPLUNK_HOME}/etc/system/local/user-seed.conf"
cat <<END > ${SPLUNK_HOME}/etc/system/local/user-seed.conf
[user_info]
USERNAME = admin
PASSWORD = ${key}
END

echo
echo "Enable splunk@system bootup"
# ${SPLUNK_BIN}/splunk enable boot-start --answer-yes --no-prompt --accept-license
# Enable System V initd rather than systemd on RHEL7 + Splunk version 7 or >
# by adding '-systemd-managed 0' in splunk enable boot-start
# For systemD, ' -systemd-managed 1'

${SPLUNK_BIN}/splunk enable boot-start -systemd-managed 1 --answer-yes --no-prompt --accept-license -user root
echo "Starting splunk..."

echo
echo "Disabling kvstore on indexer"
# Add the following to local server.conf
# [kvstore]
# disabled = true
sed -i '$a\\n\[kvstore\]\ndisabled = true\n' ${SPLUNK_LOCAL}/server.conf

# Start splunk via systemV init
systemctl start Splunkd

# Install additional packages as required by METs
echo 
echo "Installing required packages:"
yum -y install kernel-headers
yum -y install glibc-headers
yum -y install gcc
yum -y install gdb
yum -y install zip
yum -y install unzip
yum -y install nc nmap
yum -y install traceroute
rpm -q kernel-headers glibc-headers gcc gdb zip unzip nc nmap
echo
echo "Installing coredump utilities:"
rpm -q abrt-addon-ccpp >/dev/null
[[ "$?" != "0" ]] && install_abrt
echo

# Set up splunk parameters
# 1. /etc/security/limits.conf
echo
grep '262144' /etc/security/limits.conf >/dev/null
[[ "$?" != "0" ]] && {
   echo "Updating /etc/security/limits.conf"
   mv -f /etc/security/limits.conf /etc/security/limits.conf.ORIG
   {
   cat /etc/security/limits.conf.ORIG
   cat<<END_
# Begin Splunk Settings
*     soft    nofile  262144
*     hard    nofile  262144
# End Splunk Settings
END_
   } >> /etc/security/limits.conf
}

# 2. /etc/sysctl.conf
echo
grep 'fs.file-max = 2048000' /etc/sysctl.conf >/dev/null
[[ "$?" != "0" ]] && {
   echo "Updating /etc/sysctl.conf"
   mv -f /etc/sysctl.conf /etc/sysctl.conf.ORIG
   {
   cat /etc/sysctl.conf.ORIG
cat<<END__
# Begin Splunk Settings
fs.file-max = 2048000
vm.swappiness = 5
# End Splunk Settings
END__
   } >> /etc/sysctl.conf
}
sysctl -p

# 3. /etc/security/limits.d/20-nproc.conf: nproc set to 131072 per Splunk's recommendation.
echo
echo "Updating /etc/security/limits.d/20-nproc.conf"
{
cat<<END
# Default limit for number of user's processes to prevent
# accidental fork bombs.
# See rhbz #432903 for reasoning.

*          soft    nproc     131072
*          hard    nproc     131072
root       soft    nproc     unlimited
END
} > /etc/security/limits.d/20-nproc.conf

chmod 644 /etc/security/limits.d/20-nproc.conf

# On RHEL6/7, Splunk recommends to turn off Transparent Huge Pages (THP).
echo "Splunk recommends to turn off Transparent Huge Pages (THP)"
echo "Updating /etc/rc.local:"
[ -f /etc/rc.d/rc.local ] && {
  /bin/cp -p /etc/rc.d/rc.local /etc/rc.d/ORIG.rc.local
  {
    cat /etc/rc.d/ORIG.rc.local
    cat<<EOF

# On RHEL6/7, Splunk recommends to turn off Transparent Huge Pages (THP). 
# This has a profound impact on system load. There's a decent Oracle Blog 
# about it at 
# https://blogs.oracle.com/linux/entry/performance_issues_with_transparent_huge. 
# http://answers.splunk.com/answers/112305/on-rh-6-and-splunk-6-my-searches-are-consuming-lots-of-cpu
echo never > /sys/kernel/mm/transparent_hugepage/enabled
echo never > /sys/kernel/mm/transparent_hugepage/defrag

EOF
  } > /etc/rc.d/rc.local

chmod +x /etc/rc.d/rc.local
/etc/rc.d/rc.local
}
echo "COMPLETED."
cd / && umount /mnt
echo
} 2>&1 | tee /root/`basename $0`.${date_}.output
echo
echo "OUTPUT: /root/`basename $0`.${date_}.output"
