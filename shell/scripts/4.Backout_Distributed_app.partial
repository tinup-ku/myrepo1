#!/bin/ksh
##################################################################################
# This script backs out partial Splunk warm buckets, which were last distributed 
# to remote indexers' $INDEX_DATA earlier by 2.Distribute_app. It will only remove 
# warm buckets on remote indexers. Every bucket distributed is logged in source
# indexer's /opt/splunkindex_data/MIGRATED/${app}/[db|colddb]/${app}.dist
# ##########
# PROCEDURE:
# ##########
# 1. On ALL indexers where buckets were distributed, port 9990 is disabled. As root,
#    /opt/splunk/bin/splunk disable listen -port 9990 -auth admin:`uname -n`_admin
#    Note: Once port 9990 disabled, /opt/splunk/etc/system/local/inputs.conf
#          should show: disabled = 1
# 2. Stop splunkd.
# 3. Run this script
#    Usage:
#          ./3.Backout_Distributed_app.partial -f path/filename
#    Where
#    path/filename is the same input when 2.Distribute_app ran.
#
#    Output:
#          ./3.Backout_Distributed_app.partial.YYYY-MM-DD_HHMM.OUT
#
# Once back out completed, 
# 4. Start splunkd
# 5. If needed, rebuild splunk
#    /opt/splunk/bin/splunk _internal call \
#    /data/indexes/main/rebuild-metadata-and-manifests \
#    -auth admin:`uname -n`_admin
# 6. Verify via http://indexer_name.some_loc.mycorp.com:8000
#    At the search window, type
#    |dbinspect index=app_name
# 7. Enable port 9990. As root,
#    /opt/splunk/bin/splunk enable listen -port 9990 -auth admin:`uname -n`_admin
# ***** REQUIREMENTS:
# 1. remote system needs to be trusted by source system.
# 2. jldsh is needed on all systems.
# NOTE:
# 
##################################################################################
# Written by JPD.
INDEX_DATA=/opt/splunkindex_data
MIGRATED=${INDEX_DATA}/MIGRATED
date_=$(date '+%F_%H%M')

usage ()
{
cat<<END

Usage: $0 [[ -a app1,app2,app3 ]|[ -f path/filename ]]

Where: -a lists app or multiple apps separated by comma (,)
       -f and path_to_filename which shows list of apps

END
exit 1
}

backout_buckets ()
{
cat $MIGRATED/$app/$1/$2 | \
while read source dest
do
   # Parse out its node, new bucket_ID, and original bucket ID
   node=${dest%:*}
   bucket=${dest##*/}
   source_bucket=${source##*/}
   echo "Backing out ${node}:${app_location}/${bucket}"
   jldsh -ew $node "cd ${app_location};rm -rf $bucket" >/dev/null
done
   # Once backout completed, rename $MIGRATED/$app/$1/${app}.dist
   cd $MIGRATED/$app/$1 && {
       [[ -f $2 ]] && {
           echo "Rename $MIGRATED/$app/$1/$2 to $MIGRATED/$app/$1/${2}.BACKOUT.${date_}"
           /bin/mv -f $2 ${2}.BACKOUT.${date_}
       }
   }
}

#######
# MAIN
#######

if [[ "$#" = "0" ]]
then
   echo "Enter app(s) name separate by comma (,), or"
   echo -n "Filename and its location which contains apps? "
   read apps
else
   while [[ $# -gt 0 ]]
   do
     case $1 in
        -a ) apps=$2
             shift
             ;;
        -f ) apps=$2
             shift
             ;;
      -*|* )
             usage
             ;;
     esac
     shift
   done
fi

# Is it a filename or apps?
echo $apps|grep '/' >/dev/null
if [ "$?" = "0" ]
then
  # Check if file exists
  if [[ -f ${apps} ]]
  then
     apps=`awk -F: '{print $1}' ${apps}|grep -v '^#'`
     apps_=$apps
  else
     echo "${apps} doesnot exist!"
     exit 1
  fi
else
  apps=${apps//,/ }
  apps_=$apps
fi

{
date
for app in ${apps_}
do
   ###############
   # Cold buckets
   ###############
   app_location=${INDEX_DATA}/${app}/colddb
   # Check if $MIGRATED/$app/colddb/${app}.dist
   # If partial backout, no need to clean up remote indexer's cold buckets.
   [[ -f $MIGRATED/$app/colddb/${app}.dist ]] && backout_buckets colddb ${app}.dist

   ###############
   # Warm buckets
   ###############
   app_location=${INDEX_DATA}/${app}/db
   # Check if $MIGRATED/$app/db/${app}.dist
   [[ -f $MIGRATED/$app/db/${app}.dist ]] && backout_buckets db ${app}.dist
done
date
} 2>&1 | tee `basename $0`.${date_}.OUT 

echo
echo "OUTPUT: $0.${date_}.OUT"

